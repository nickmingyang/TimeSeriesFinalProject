---
title: "TS_FinalProject_Ferraro_Norelli_YU"
author: "Ricco, Nicole & Nick"
date: '2022-03-26'
output: html_document
---

```{r setup, include=FALSE, warning= FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
The objective of this analysis is to model and forecast electricity pricing time series data in the Dallas, TX area.
Our client is the Dallas local government, and they have requested the forecasts for economic and infrastructure planning.
The electricity pricing data is from the St. Louis Federal Reserve. We chose to model the data from January 2000 to present. Data from earlier dates had different behavior because it was before Texas deregulated electricity pricing.
This analysis explores the use of univariate and multivariate time series models. The multivariate models include the addition of the variables Dallas temperature, Dallas gasoline prices, and southern urban consumer price index (CPI). These additional variables were obtained from the National Weather Service, the St. Louis Federal Reserve, and the Bureau of Labor Statistics.
Univariate methods include various ARIMA models and signal plus noise. Multivariate methods include VAR, neural network (MLP), and ensemble models.

## Data Read in & Wrangling
- This part is for reading in all related data frame, cleaning them extracting all data from 2000-1 - 2022-02 time period
- The resulting data frame is stored under 'df' variable
- You can run whole chunk directly after fixed file location

```{r, warning= FALSE, message=FALSE}

library(tswge)
library(dplyr)
library(tidyverse)
library(readxl)
library(vars)
library(nnfor)
# Set this to data folder for your file
#setwd("/Users/riccoferraro/Documents/SMU/TimeSeries/TimeSeriesFinalProject/data")
setwd("/Users/mingyang/Desktop/SMU/TimeSeries/TimeSeriesFinalProject/data")
# Read in DFWA electricity Data
dfwa.electricity = read.csv("AVG_ELEC_DFWA_TX.csv",col.names = c("DATE", "AVG_EP"), 
                          colClasses = c(DATE="character", AVG_EP="character"))

# Read in CPI data for Southern Urban area
cpi = read_excel("SouthernUrbanCPI.xlsx",sheet = "BLS Data Series", skip = 11)
# Getting rid of Half1 and Half2 which starts with S
cpi = cpi %>% filter(!grepl('S',Period) )
# Getting rid of Annual which labeled as M13
cpi = cpi %>% filter(!grepl('M13',Period) )

# Read in Gas Price data from same area
gas.price = read.csv("Dallas_FWA_GAS.csv")

# Read in Temperature Data & cleaning
temp = read_excel("DallasAreaTemp.xlsx", sheet = "Sheet1")
temp = temp %>% tidyr::pivot_longer(
  cols = starts_with("Mon_"),
  names_to = "Month",
  values_to = "Temperature"
)
temp = temp[1:386,]

# subset dataset
# which(dfwa.electricity$DATE=="1990-01-01") # 135
dfwa.electricity = dfwa.electricity[135:520,]
rownames(dfwa.electricity) <- 1:nrow(dfwa.electricity)

# which(cpi$Year==1990 & cpi$Period=="M01")
cpi = cpi[91:476,]
rownames(cpi) <- 1:nrow(cpi)

# which(gas.price$DATE=="1990-01-01") # 145
gas.price = gas.price[145:530,]
rownames(gas.price) <- 1:nrow(gas.price)


#### Creating ultimate data frame under variable 'df' ####
df = dfwa.electricity
df$CPI = cpi$Value
df$GAS_P = gas.price$APUS37A7471A
df$AVG_EP = as.numeric(df$AVG_EP)
df$TEMP = temp$Temperature

#### Due to distribution market deregulation in 1995, team decided to cut the realization
#### prior to 2000
# which(df$DATE=="2000-01-01") # 121
df = df[121:386,]
rownames(df) <- 1:nrow(df)

```

#### Average Electricity Price vs. Time
```{r}
plotts.wge(df$AVG_EP)
```

#### Average CPI vs. Time
```{r}
plotts.wge(df$CPI)

```

#### Average Gas Price vs. Time
```{r}
plotts.wge(df$GAS_P)

```

#### Temperature vs. Time
```{r}
plotts.wge(df$TEMP)
```

## Modeling and Forecasting
#### EDA and Univariate Modeling
- Short term forecast horizon is determined to be 3 month since it might be helpful for short term enerage usage planning
- Long term forecast horizen is determined to be 36 month, since it is helpful to forecast pricing few years out for infrastructure and budget planning

```{r}
# There seem to be a slowly damping behavior which might support difference the data
fig1 = plotts.sample.wge(df$AVG_EP)

# Try overfitting
est = est.ar.wge(df$AVG_EP, p=16, type='burg')
# compare this to seasonality of 12 
factor.wge(phi = c(rep(0,11),1))

# By using overfitting method, 1-B term seems to have the largest absolute reciprocal root which by itself supports differencing the data
# Additionally, there seem to have a 1-B^12 seasonality, even some of the factors such as 1+B at system frequency of -.5 and 1+1.73B+1B^2 at System frequency of 0.4167 are not as close to the unit circle. Although it might worth exploring s = 12 also

d1 = artrans.wge(df$AVG_EP, phi.tr = 1)
# with the differenced data there seem to have some sort of seasonal behavior at 12 left
d1.12 = artrans.wge(d1, phi.tr = c(rep(0,11),0.4))
par(mfrow=c(1,1))
acf(d1.12) # AIC looks about white noise
ljung.wge(d1.12, K=24) # K=24 reject white noise hypothesis
ljung.wge(d1.12, K=48) # K = 48 reject white noise 
# Thus models require further modeling

# est1.12 = aic5.wge(d1.12, p=0:15, q=0:5) # AIC picked p = 7, q=4
# est.1.12.bic = aic5.wge(d1.12, p=0:15, q=0:5, type = 'bic') # bic picked p=0, q=0
# est.1.12.aicc = aic5.wge(d1.12, p=0:15, q=0:5, type = 'aicc') # aicc picked p=1, q=0
# seems AIC leaning towards a fancy model, while bic leaning towards white noise.
# I will attempt something in the middle by using AR(1) instead
params.est = est.arma.wge(d1.12, p=1)

acf(params.est$res) # residuals looks about white noise
ljung.wge(params.est$res, K=24) # K=24 reject white noise hypothesis
ljung.wge(params.est$res, K=48) # K = 48reject null hypothesis of white noise

# Try fancier model identified by AIC
params.est = est.arma.wge(d1.12, p=7,q=4)
acf(params.est$res) # residuals looks about white noise
ljung.wge(params.est$res, K=24) # K=24 fail to reject white noise hypothesis
ljung.wge(params.est$res, K=48) # K = 48 fail to reject null hypothesis of white noise

# All models are wrong some are useful - we will proceed with fancier model for now
model1.param = mult.wge(fac1 = params.est$phi, fac2 = c(rep(0,11),0.4))
pred.short = fore.arima.wge(df$AVG_EP, phi = model1.param$model.coef, theta = params.est$theta,
                            d = 1, n.ahead = 3, limits = T, lastn = T)
ASE.short = mean((df$AVG_EP[264:266]-pred.short$f)^2)
ASE.short # 3.184093e-05 -> 0.0000318  #New 5.988891e-05 -> 0.0000599

pred.long = fore.arima.wge(df$AVG_EP, phi = model1.param$model.coef, theta = params.est$theta,
                            d = 1, n.ahead = 36, limits = T, lastn = T)
ASE.long = mean((df$AVG_EP[(266-36+1):266]-pred.long$f)^2)
ASE.long # 0.0001725023

# rolling.res.short = roll.win.rmse.wge(df$AVG_EP,phi = model1.param$model.coef, theta = params.est$theta, d = 1, horizon = 3 )
# rolling.res.short # RMSE = 0.004, ASE = 1.6e-0.5 -> 0.000016, nums of windows = 239

# rolling.res.long = roll.win.rmse.wge(df$AVG_EP,phi = model1.param$model.coef, theta = params.est$theta, d = 1, horizon = 36)
# rolling.res.long # RMSE = 0.014, ASE= 0.000196, num of windows = 206

```


#### Forecasting with all training data available to the future

```{r}
pred.all.short = fore.arima.wge(df$AVG_EP, phi = model1.param$model.coef, theta = params.est$theta,
                            d = 1, n.ahead = 3, limits = T, lastn = F)

pred.all.long = fore.arima.wge(df$AVG_EP, phi = model1.param$model.coef, theta = params.est$theta,
                            d = 1, n.ahead = 36, limits = T, lastn = F)
```

#### Univariate signal plus noise model
- This section created a signal plus noise model. However, was not utilized as the final model during presentation
- There is no rolling window ASE to be used for comparison with other models only test ASE

```{r}
x = df$AVG_EP
n = length(x)
t = 1:n
d = lm(x~t)
# x.z are the residuals from the regression line
x.z = x-d$coefficients[1] - d$coefficients[2]*t
fig2 = plotts.sample.wge(x.z)

ar.z = aic.wge(x.z, p=0:15)
x.trans = artrans.wge(x, phi.tr = ar.z$phi)
t.trans = artrans.wge(t, phi.tr = ar.z$phi)
fit = lm(x.trans~ t.trans)
summary(fit)
# As can be seen, after account for the serial correlation (AR(14)), there is strong evidence to suggest that the slope is significantly different from zero (pvalue < 0.0001). So we will take the trend out and proceed

# try bootstrapping method just to be sure
wbg.boot.wge(x, sn=103)
# Bootstrap-based test for trend failed to reject with p-value = 0.1078, however we will proceed to try out how using trend helps
ar.est = est.ar.wge(x = x.z, p=14, type = 'burg')
par(mfrow=c(1,1))
acf(ar.est$res)
ljtest.3 = ljung.wge(ar.est$res)
ljtest.4 = ljung.wge(ar.est$res, K=48)
# both tests reject white noise
m2.result = fore.sigplusnoise.wge(x, linear = TRUE, max.p = 15, n.ahead = 3, lastn = TRUE, limits=TRUE)
ASE.short.m2 = mean((df$AVG_EP[264:266]-m2.result$f)^2)
ASE.short.m2 # 6.718437e-05 -> 0.0000672
m2.result.long = fore.sigplusnoise.wge(x, linear = TRUE, max.p = 15, n.ahead = 36, lastn = TRUE, limits=TRUE)
ASE.long.m2 = mean((df$AVG_EP[(266-36+1):266]-m2.result.long$f)^2)
ASE.long.m2 # 0.0001268439

```

#### Multivariate - VAR model

```{r}
train.var = df[1:230,2:5]
test.var = df[231:266,2:5]

# Prior to fitting looking at correlation plot to get an idea
ccf(train.var$CPI, train.var$AVG_EP)
# Looks like Gas Price lag2 is most correlated with electricity price
ccf(train.var$GAS_P, train.var$AVG_EP)
# lag 0 or 1 of temperature seems most correlated with electricity price ( although this correlation is weaker compared to Gas and CPI)
ccf(train.var$TEMP, train.var$AVG_EP)

# AIC and FPE selected lag = 11, Schwarz Criterion selected lag = 6, Hannan Quinn Criterion selected lag = 3
# Try them all and compare their short term and long term ASE
VARselect(train.var, lag.max=15, type="both", season = NULL, exogen = NULL)
# Try lag = 11
lsfit.p11 = VAR(train.var, p = 11, type ="both")
preds.p11.short = predict(lsfit.p11, n.ahead = 3)
preds.p11.long = predict(lsfit.p11, n.ahead = 36)

test_ASE_p11_short = mean((preds.p11.short$fcst$AVG_EP[,1]-test.var$AVG_EP[1:3])^2)
test_ASE_p11_short # 1.40152e-05 -> 0.000014

test_ASE_p11_long = mean((preds.p11.long$fcst$AVG_EP[,1]-test.var$AVG_EP[1:36])^2)
test_ASE_p11_long # 0.0001447111

# Try lag = 6
lsfit.p6 = VAR(train.var, p = 6, type ="both")
preds.p6.short = predict(lsfit.p6, n.ahead = 3)
preds.p6.long = predict(lsfit.p6, n.ahead = 36)

test_ASE_p6_short = mean((preds.p6.short$fcst$AVG_EP[,1]-test.var$AVG_EP[1:3])^2)
test_ASE_p6_short # 9.127952e-06 -> 0.00000913

test_ASE_p6_long = mean((preds.p6.long$fcst$AVG_EP[,1]-test.var$AVG_EP[1:36])^2)
test_ASE_p6_long # 0.0001166065

# Try lag = 3
lsfit.p3 = VAR(train.var, p = 3, type ="both")
preds.p3.short = predict(lsfit.p3, n.ahead = 3)
preds.p3.long = predict(lsfit.p3, n.ahead = 36)

test_ASE_p3_short = mean((preds.p3.short$fcst$AVG_EP[,1]-test.var$AVG_EP[1:3])^2)
test_ASE_p3_short # 2.780987e-06 -> 0.000002781

test_ASE_p3_long = mean((preds.p3.long$fcst$AVG_EP[,1]-test.var$AVG_EP[1:36])^2)
test_ASE_p3_long # 9.241909e-05 -> 0.00009242

```

#### Visualization for VAR best model lag = 3

```{r}
# Short Term Forecast - VAR best model

t = 200:233
plot(t, df$AVG_EP[200:233], type='o',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(200, 236),ylim=c(0.10,0.16),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.1,1.1,1.1),text=c("Time","Price",""),line=c(1.2,2.1,1.8))
title("Short Term Average Electricity Price Forecast VAR")
points(230:233,c(df$AVG_EP[230:230],preds.p3.short$fcst$AVG_EP[,1]),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)
points(230:233,c(df$AVG_EP[230:230],preds.p3.short$fcst$AVG_EP[,3]),type='l',lty=3,cex=0.6,lwd=2,pch=1,col='blue3')
points(230:233,c(df$AVG_EP[230:230],preds.p3.short$fcst$AVG_EP[,2]),type='l',lty=3,cex=0.6,lwd=2,pch=1,col='blue3')

# Long Term Forecast - VAR best model

t = 1:266
plot(t, df$AVG_EP[1:266], type='l',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(1, 266),ylim=c(0.05,0.18),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.0,1.0,1.0),text=c("Time","Price",""),line=c(1.2,2.1,1.8))
title("Long Term Average Electricity Price Forecast VAR")
points(230:266,c(df$AVG_EP[230:230],preds.p3.long$fcst$AVG_EP[,1]),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)
points(230:266,c(df$AVG_EP[230:230],preds.p3.long$fcst$AVG_EP[,3]),type='l',lty=3,cex=0.6,lwd=2,pch=1,col='blue3')
points(230:266,c(df$AVG_EP[230:230],preds.p3.long$fcst$AVG_EP[,2]),type='l',lty=3,cex=0.6,lwd=2,pch=1,col='blue3')

```

#### Forecasting out short and Long term with all training data

```{r}
VARselect(df[,2:5], lag.max = 15, type = "both")
var.model = VAR(df[,2:5], p=3,type = "both")
forecast.3month = predict(var.model, n.ahead = 3)
forecast.36month = predict(var.model, n.ahead = 36)
# Plot Short Term
t = 250:266
plot(t, df$AVG_EP[250:266], type='o',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(250, 270),ylim=c(0.12,0.18),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.1,1.1,1.1),text=c("Time","",""),line=c(1.2,2.1,1.8))
title("Short Term Average Electricity Price Forecast VAR")
points(266:269,c(df$AVG_EP[266:266],forecast.3month$fcst$AVG_EP[,1]),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)
points(266:269,c(df$AVG_EP[266:266],forecast.3month$fcst$AVG_EP[,3]),type='l',lty=3,cex=0.6,lwd=2,pch=1,col='blue3')
points(266:269,c(df$AVG_EP[266:266],forecast.3month$fcst$AVG_EP[,2]),type='l',lty=3,cex=0.6,lwd=2,pch=1,col='blue3')

t = 1:266
plot(t, df$AVG_EP[1:266], type='l',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(1, 302),ylim=c(0.05,0.25),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.0,1.0,1.0),text=c("Time","",""),line=c(1.2,2.1,1.8))
title("Long Term Average Electricity Price Forecast VAR")
points(266:302,c(df$AVG_EP[266:266],forecast.36month$fcst$AVG_EP[,1]),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)
points(266:302,c(df$AVG_EP[266:266],forecast.36month$fcst$AVG_EP[,3]),type='l',lty=3,cex=0.6,lwd=2,pch=1,col='blue3')
points(266:302,c(df$AVG_EP[266:266],forecast.36month$fcst$AVG_EP[,2]),type='l',lty=3,cex=0.6,lwd=2,pch=1,col='blue3')

```

#### Multi Layer Perceptural - Neural Network Model
-Forecast final 36 values for temperature, gas, and CPI using univariate MLP models.
-Use these predictions in multivariate MLP model to predict final 36 electricity values.

```{r}
df.train = ts(df[1:230,2], start = c(2000,1), frequency = 12)
df.test = ts(df[231:266,2], start=c(2019,3), frequency = 12)

other.predictors.train = df[1:230,3:5]
set.seed(2)
fit.mlp1 = mlp(df.train, reps = 20, comb = "median", xreg = other.predictors.train,
               xreg.lags = c(1,1,1), allow.det.season = FALSE, hd = 5, difforder = 0, sel.lag = FALSE)
fit.mlp1
plot(fit.mlp1)

# Forecast next 36 CPI
set.seed(2)
fit.mlp.cpi = mlp(ts(df$CPI[1:230], start = c(2000,1), frequency = 12), reps = 20, comb = "median",
                  allow.det.season = TRUE)
fore.mlp.cpi = forecast(fit.mlp.cpi, h=36)
plot(fore.mlp.cpi)
# Forecast next 36 Gas_P
set.seed(2)
fit.mlp.gas = mlp(ts(df$GAS_P[1:230], start = c(2000,1), frequency = 12), reps = 20, comb = "median",
                  allow.det.season = TRUE)
fore.mlp.gas = forecast(fit.mlp.gas, h=36)
plot(fore.mlp.gas)

# Forecast next 36 Temperature
set.seed(2)
fit.mlp.temp = mlp(ts(df$TEMP[1:230], start = c(2000,1), frequency = 12), reps = 20, comb = "median",
                  allow.det.season = TRUE)
fore.mlp.temp = forecast(fit.mlp.temp, h=36)
plot(fore.mlp.temp)

other.predictors.with.forecast = data.frame(CPI = c(df$CPI[1:230],fore.mlp.cpi$mean[1:36]),
                                            GAS_P = c(df$GAS_P[1:230],fore.mlp.gas$mean[1:36]),
                                            GAS_P = c(df$TEMP[1:230],fore.mlp.temp$mean[1:36]))
fore.mlp1.short = forecast(fit.mlp1, h=3, xreg = other.predictors.with.forecast)
test_ASE_mlp1_short = mean((fore.mlp1.short$mean[1:3]-df$AVG_EP[231:233])^2)
test_ASE_mlp1_short # 1.947679e-05 -> 0.00001947

fore.mlp1.long = forecast(fit.mlp1, h=36, xreg = other.predictors.with.forecast)
test_ASE_mlp1_long = mean((fore.mlp1.long$mean[1:36]-df$AVG_EP[231:266])^2)
test_ASE_mlp1_long # 0.000111

```

#### Visualization for NN Model

```{r}
# Short Term Forecast - MLP model
t = 200:233
plot(t, df$AVG_EP[200:233], type='o',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(200, 236),ylim=c(0.10,0.16),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.1,1.1,1.1),text=c("Time","Price",""),line=c(1.2,2.1,1.8))
title("Short Term Average Electricity Price Forecast MLP")
points(230:233,c(df$AVG_EP[230:230],fore.mlp1.short$mean[1:3]),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)


# Long Term Forecast - VAR best model
t = 1:266
plot(t, df$AVG_EP[1:266], type='l',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(1, 266),ylim=c(0.05,0.18),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.0,1.0,1.0),text=c("Time","Price",""),line=c(1.2,2.1,1.8))
title("Long Term Average Electricity Price Forecast MLP")
points(230:266,c(df$AVG_EP[230:230],fore.mlp1.long$mean[1:36]),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)

```

#### Testing Neural Network Short Term Long term Forecasting With all training data

```{r}
df.mlp.train = ts(df[1:266,2], start = c(2000,1), frequency = 12)

other.predictors.mlp.train = df[1:266,3:5]
set.seed(2)
fit.all.mlp = mlp(df.mlp.train, reps = 20, comb = "median", xreg = other.predictors.mlp.train,
               xreg.lags = c(1,1,1), allow.det.season = FALSE, hd = 5, difforder = 0, sel.lag = FALSE)
fit.all.mlp
plot(fit.all.mlp)

# Forecast next 36 CPI
set.seed(2)
fit.mlp.all.cpi = mlp(ts(df$CPI[1:266], start = c(2000,1), frequency = 12), reps = 20, comb = "median",
                  allow.det.season = TRUE)
fore.mlp.all.cpi = forecast(fit.mlp.all.cpi, h=36)
plot(fore.mlp.all.cpi)
# Forecast next 36 Gas_P
set.seed(2)
fit.mlp.all.gas = mlp(ts(df$GAS_P[1:266], start = c(2000,1), frequency = 12), reps = 20, comb = "median",
                  allow.det.season = TRUE)
fore.mlp.all.gas = forecast(fit.mlp.all.gas, h=36)
plot(fore.mlp.all.gas)

# Forecast next 36 Temperature
set.seed(2)
fit.mlp.all.temp = mlp(ts(df$TEMP[1:266], start = c(2000,1), frequency = 12), reps = 20, comb = "median",
                  allow.det.season = TRUE)
fore.mlp.all.temp = forecast(fit.mlp.all.temp, h=36)
plot(fore.mlp.all.temp)

other.predictors.with.forecast = data.frame(CPI = c(df$CPI[1:266],fore.mlp.all.cpi$mean[1:36]),
                                            GAS_P = c(df$GAS_P[1:266],fore.mlp.all.gas$mean[1:36]),
                                            GAS_P = c(df$TEMP[1:266],fore.mlp.all.temp$mean[1:36]))
# Short Term forecast with MLP
fore.mlp.all.short = forecast(fit.all.mlp, h=3, xreg = other.predictors.with.forecast)

# Long term forecast with MLP
fore.mlp.all.long = forecast(fit.all.mlp, h=36, xreg = other.predictors.with.forecast)


```

#### Visualization for MLP Short and Long term forecast with all training data

```{r}
t = 250:266
plot(t, df$AVG_EP[250:266], type='o',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(250, 270),ylim=c(0.12,0.18),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.1,1.1,1.1),text=c("Time","",""),line=c(1.2,2.1,1.8))
title("Short Term Average Electricity Price Forecast MLP")
points(266:269,c(df$AVG_EP[266:266],fore.mlp.all.short$mean[1:3]),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)

t = 1:266
plot(t, df$AVG_EP[1:266], type='l',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(1, 302),ylim=c(0.05,0.185),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.0,1.0,1.0),text=c("Time","",""),line=c(1.2,2.1,1.8))
title("Long Term Average Electricity Price Forecast MLP")
points(266:302,c(df$AVG_EP[266:266],fore.mlp.all.long$mean[1:36]),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)

```

#### Ensemble ARIMA(7,1,4), Best VAR and MLP (With test data)

```{r}
ensemble.forecast.short = (pred.short$f+preds.p3.short$fcst$AVG_EP[,1]+fore.mlp1.short$mean[1:3])/3
test_ASE_ensemble1.short = mean((ensemble.forecast.short-df$AVG_EP[231:233])^2)
test_ASE_ensemble1.short # 3.312542e-06 -> 0.0000033

ensemble.forecast.long = (pred.long$f+preds.p3.long$fcst$AVG_EP[,1]+fore.mlp1.long$mean[1:36])/3
test_ASE_ensemble1.long = mean((ensemble.forecast.long-df$AVG_EP[231:266])^2)
test_ASE_ensemble1.long # 7.819804e-05 -> 0.0000782
```

#### Visualization for Ensemble Model With Test Data Excluded (ARIMA, VAR and MLP)

```{r}
# Short Term Forecast - Ensemble model
t = 200:233
plot(t, df$AVG_EP[200:233], type='o',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(200, 236),ylim=c(0.10,0.16),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.1,1.1,1.1),text=c("Time","Price",""),line=c(1.2,2.1,1.8))
title("Short Term Average Electricity Price Forecast Ensemble")
points(230:233,c(df$AVG_EP[230:230],ensemble.forecast.short),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)


# Long Term Forecast - Ensemble best model
t = 1:266
plot(t, df$AVG_EP[1:266], type='l',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(1, 266),ylim=c(0.05,0.18),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.0,1.0,1.0),text=c("Time","Price",""),line=c(1.2,2.1,1.8))
title("Long Term Average Electricity Price Forecast Ensemble")
points(230:266,c(df$AVG_EP[230:230],ensemble.forecast.long),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)

```

#### Ensemble ARIMA(7,1,4) and MLP (With test data)

```{r}
ensemble.forecast.short = (pred.short$f+fore.mlp1.short$mean[1:3])/2
test_ASE_ensemble1.short = mean((ensemble.forecast.short-df$AVG_EP[231:233])^2)
test_ASE_ensemble1.short # 1.079313e-05 -> 0.00001079

ensemble.forecast.long = (pred.long$f+fore.mlp1.long$mean[1:36])/2
test_ASE_ensemble1.long = mean((ensemble.forecast.long-df$AVG_EP[231:266])^2)
test_ASE_ensemble1.long # 7.769396e-05 -> 0.00007769
```

#### Visualization for Ensemble Model With Test Data Excluded (ARIMA and MLP)

```{r}
# Short Term Forecast - Ensemble model
t = 200:233
plot(t, df$AVG_EP[200:233], type='o',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(200, 236),ylim=c(0.10,0.16),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.1,1.1,1.1),text=c("Time","Price",""),line=c(1.2,2.1,1.8))
title("Short Term Average Electricity Price Forecast Ensemble")
points(230:233,c(df$AVG_EP[230:230],ensemble.forecast.short),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)


# Long Term Forecast - Ensemble best model
t = 1:266
plot(t, df$AVG_EP[1:266], type='l',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(1, 266),ylim=c(0.05,0.18),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.0,1.0,1.0),text=c("Time","Price",""),line=c(1.2,2.1,1.8))
title("Long Term Average Electricity Price Forecast Ensemble")
points(230:266,c(df$AVG_EP[230:230],ensemble.forecast.long),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)

```

#### Ensemble ARIMA(7,1,4) and MLP (VAR excluded due to explosive behavior for long term prediction)

```{r}
ensemble.all.short = (pred.all.short$f+fore.mlp.all.short$mean[1:3])/2
ensemble.all.long = (pred.all.long$f+fore.mlp.all.long$mean[1:36])/2

```

#### Visualization for ensemble to forecast future using all training data

```{r}
t = 250:266
plot(t, df$AVG_EP[250:266], type='o',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(250, 270),ylim=c(0.12,0.18),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.1,1.1,1.1),text=c("Time","",""),line=c(1.2,2.1,1.8))
title("Short Term Average Electricity Price Forecast Ensemble")
points(266:269,c(df$AVG_EP[266:266],ensemble.all.short),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)

t = 1:266
plot(t, df$AVG_EP[1:266], type='l',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(1, 302),ylim=c(0.05,0.185),col=1)
axis(side=1,cex.axis=1.0,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.0,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.0,1.0,1.0),text=c("Time","",""),line=c(1.2,2.1,1.8))
title("Long Term Average Electricity Price Forecast Ensemble")
points(266:302,c(df$AVG_EP[266:266],fore.mlp.all.long$mean[1:36]),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)


```


## Conclusion
The final recommendation for short-term (3 month) forecasting is the VAR model with p=3. It had the best short-term test ASE of all models explored. The final recommendation for long-term (36 month) forecasting is an ensemble model that equally combines the ARIMA(7,1,4) s=12 with coefficient of 0.4 and the best MLP model. This ensemble had the best long-term (36 month) test ASE and its future forecasts looked promising.



## Appendix

#### Visualization code 

```{r eval = FALSE, echo = TRUE}
library(ggplot2)
df[['DATE']] <- as.Date(df[['DATE']], format='%Y-%m-%d')

# Convert short term prediction to dataframe
pred.short = fore.arima.wge(df$AVG_EP, phi = model1.param$model.coef, theta = params.est$theta,
                            d = 1, n.ahead = 3, limits = T, lastn = F)
dev.off()
t = 250:266
plot(t, df$AVG_EP[250:266], type='o',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(250, 270),ylim=c(0.12,0.175),col=1)
axis(side=1,cex.axis=1.1,mgp=c(3,0.15,0),tcl=-.3)
axis(side=2,las=1,cex.axis=1.1,mgp=c(3,.4,0),tcl=-.3)
mtext(side=c(1,2,1),cex=c(1.2,1.2,1.2),text=c("Time","",""),line=c(1.2,2.1,1.8))
points(266:269,c(df$AVG_EP[266:266],f.short.15.5$f),type='o',lty=1,cex=.6,lwd=1,pch=1,col=2)
points(266:269,c(df$AVG_EP[266:266],f.short.15.5$ul),type='l',lty=3,cex=0.6,lwd=2,pch=1,col='blue3')
points(266:269,c(df$AVG_EP[266:266],f.short.15.5$ll),type='l',lty=3,cex=0.6,lwd=2,pch=1,col='blue3')

pred.long = fore.arima.wge(df$AVG_EP, phi = model1.param$model.coef, theta = params.est$theta,
                            d = 1, n.ahead = 36, limits = T, lastn = F)

pred.short.df = data.frame(Date = df$DATE[264:266], prediction = pred.short$f, upper = pred.short$ul, lower = pred.short$ll)

colors <- c("Actual Price" = "#00AFBB", "Predicted Price" = "#FC4E07", "Prediction Limit"= "#E7B800")

# Original TS plot:
ggplot(data = df[1:266,], aes(x=DATE, y=AVG_EP))+
  geom_line(color="#00AFBB", size = 1) +
  geom_point(color="#00AFBB") +
  ggtitle("Electricity Price Over time")+xlab("Date")+ylab("Average Price") + theme_classic()


ggplot(data = df[260:266,], aes(x=DATE, y=AVG_EP, color="Actual Price"))+
  geom_line( size = 1) +
  ggtitle("Short term average Electricity price forecast")+xlab("Date")+ylab("Average Price") +
  geom_line(data = pred.short.df,aes(x=Date, y=prediction), color="#FC4E07", size=1.1) +
  geom_point(data = pred.short.df,aes(x=Date, y=prediction), color="#FC4E07", size=1.5)+
  geom_line(data = pred.short.df,aes(x=Date, y=upper), color="#E7B800", size=1.1)+
  geom_point(data = pred.short.df,aes(x=Date, y=upper), color="#E7B800", size=1.1)+
  geom_line(data = pred.short.df,aes(x=Date, y=lower), color="#E7B800", size=1.1)+ 
  geom_point(data = pred.short.df,aes(x=Date, y=lower), color="#E7B800", size=1.1)+
  scale_color_manual(values = colors) + theme_classic()

```

#### Additional Models - Nicole

```{r}
plotts.sample.wge(df$AVG_EP)
# slowly damping autocorrelations
# spectral density peaks at 0 (wandering behavior)
# possible seasonal peak at 1/12 = .0833333 (monthly)
# est.ar.wge(df$AVG_EP,p=15,type="burg")
# factor.wge(phi=c(rep(0,11),1))
# some evidence of s=12 in overfit, though Abs Recip should be a higher

# take difference and look at acf
AVE_EP_d1 = artrans.wge(df$AVG_EP,phi.tr=1)
dev.off()
acf(AVE_EP_d1)
plotts.sample.wge(AVE_EP_d1)
# characteristic seasonal component for 12 months (ACF large at multiples of 12)
AVE_EP_d1_s12 = artrans.wge(AVE_EP_d1,phi.tr=c(rep(0,11),1))
plotts.sample.wge(AVE_EP_d1_s12)
dev.off()
acf(AVE_EP_d1_s12)
# doesn't look like white noise
# aic5.wge(AVE_EP_d1_s12,p=0:15) #13,0 12,2 12,0
EP_est = est.arma.wge(AVE_EP_d1_s12,p=12)

# short 3 month ARUMA(12,1,0) s=12
# roll.win.ase.wge(df$AVG_EP,horizon=3,s=12,d=1,phis=EP_est$phi,thetas=EP_est$theta)
#   2.8495e-05 -> 0.0000285
f.short = fore.arima.wge(df$AVG_EP,phi=EP_est$phi,theta=EP_est$theta,s=12,d=1,n.ahead=3,lastn=TRUE)
ASE.short = mean((df$AVG_EP[264:266]-f.short$f)^2)
ASE.short #3.595854e-05 -> 0.000036

# long 36 month ARUMA(12,1,0) s=12
# roll.win.ase.wge(df$AVG_EP,horizon=36,s=12,d=1,phis=EP_est$phi,thetas=EP_est$theta)
# 0.0004547268
f.long = fore.arima.wge(df$AVG_EP,phi=EP_est$phi,theta=EP_est$theta,s=12,d=1,n.ahead=36,lastn=TRUE)
ASE.long = mean((df$AVG_EP[(266-36+1):266]-f.long$f)^2)
ASE.long 
#0.001223659

# try other AIC5 options with long forecast: ARUMA(13,1,0) s=12 
EP_est_13 = est.arma.wge(AVE_EP_d1_s12,p=13)
# roll.win.ase.wge(df$AVG_EP,horizon=36,s=12,d=1,phis=EP_est_13$phi,thetas=EP_est_13$theta)
#   0.0004697769
f = fore.arima.wge(df$AVG_EP,phi=EP_est_13$phi,theta=EP_est_13$theta,s=12,d=1,n.ahead=36,lastn=TRUE)
mean((df$AVG_EP[(266-36+1):266]-f$f)^2)
#0.001237814

# try 12,2 ARUMA(12,1,2) s=12
EP_est_12_2 = est.arma.wge(AVE_EP_d1_s12,p=12,q=2)
# roll.win.ase.wge(df$AVG_EP,horizon=36,s=12,d=1,phis=EP_est_12_2$phi,thetas=EP_est_12_2$theta)
#  0.0004835913
f = fore.arima.wge(df$AVG_EP,phi=EP_est_12_2$phi,theta=EP_est_12_2$theta,s=12,d=1,n.ahead=36,lastn=TRUE)
mean((df$AVG_EP[(266-36+1):266]-f$f)^2) 
# 0.00128316

# None of these beat Nick's ARUMA(13,1,5) s=12

# Try another model entirely - take 1st diff then fit an ARMA
AVE_EP_d1 = artrans.wge(df$AVG_EP,phi.tr=1)
# aic5.wge(AVE_EP_d1,p=0:15,q=0:5) #15,5
# aic5.wge(AVE_EP_d1,p=10:20,q=0:5) #15,5
# aic5.wge(AVE_EP_d1,p=0:15,q=0:5,type="bic") #12,0 13,1

# ARIMA(15,1,5)
EP_est_15_5 = est.arma.wge(AVE_EP_d1,p=15,q=5)
# short 3 month
# roll.win.ase.wge(df$AVG_EP,horizon=3,d=1,phis=EP_est_15_5$phi,thetas=EP_est_15_5$theta)
#   3.695999e-05
dev.off()
f.short.15.5 = fore.arima.wge(df$AVG_EP,phi=EP_est_15_5$phi,theta=EP_est_15_5$theta,d=1,n.ahead=3,lastn=TRUE)
ASE.short = mean((df$AVG_EP[264:266]-f.short.15.5$f)^2)
ASE.short #4.216765e-05 -> 0.000042167

# 36 month ARIMA(15,1,5)
# roll.win.ase.wge(df$AVG_EP,horizon=36,d=1,phis=EP_est_15_5$phi,thetas=EP_est_15_5$theta)
# 0.0002368869
f.long.15.5 = fore.arima.wge(df$AVG_EP,phi=EP_est_15_5$phi,theta=EP_est_15_5$theta,d=1,n.ahead=36,lastn=TRUE)
ASE.long = mean((df$AVG_EP[(266-36+1):266]-f.long.15.5$f)^2)
ASE.long 
# 0.0001089089

# ARIMA(12,1,0)
EP_est_12_0 = est.arma.wge(AVE_EP_d1,p=12)
# short 3 month
# roll.win.ase.wge(df$AVG_EP,horizon=3,d=1,phis=EP_est_12_0$phi)
#  2.661653e-05
f.short.12.0 = fore.arima.wge(df$AVG_EP,phi=EP_est_12_0$phi,d=1,n.ahead=3,lastn=TRUE)
ASE.short = mean((df$AVG_EP[264:266]-f.short.12.0$f)^2)
ASE.short # 8.029078e-05 -> 0.0000803

# 36 month ARIMA(12,1,0)
# roll.win.ase.wge(df$AVG_EP,horizon=36,d=1,phis=EP_est_12_0$phi)
# 0.0002323361
f.long.12.0 = fore.arima.wge(df$AVG_EP,phi=EP_est_12_0$phi,d=1,n.ahead=36,lastn=TRUE)
ASE.long = mean((df$AVG_EP[(266-36+1):266]-f.long.12.0$f)^2)
ASE.long 
# 0.0001502498


```

#### Trial - Ricco

```{r eval = FALSE, echo = TRUE}
plotts.sample.wge(df$AVG_EP)

## over-fit like our lives depend on it
overfit_ar_30_ricco=est.ar.wge(df$AVG_EP,p=50, type='burg')

# Clearly a 1-B in there. try removing it and over-fitting again. 
AVG_E_i1_ricco = artrans.wge(df$AVG_EP, c(1))
overfit_ar_30_i1_ricco=est.ar.wge(AVG_E_i1_ricco,p=20, type='burg')
# nonstationary_lambda = mult.wge(fac1=c(1-1.7276B+0.9942B^2), c(1+0.9951B), c(1+0.0130B+0.9896B^2), c(1+0.9916B+0.9889B^2))
nonstationary_lambda_ricco = mult.wge(c(1.7276,-0.9942), c(-0.9951), c(-0.0130,-0.9896), c(-0.9916,-0.9889))
nonstationary_lambda$model.coef
AVG_E_lambda_corrected_ricco = artrans.wge(df$AVG_EP, c(nonstationary_lambda$model.coef))
aic_lambda_corrected_ricco = aic.wge(AVG_E_lambda_corrected_ricco, p=0:12, q=0:5, type="bic")
forecast_arma = fore.aruma.wge(df$AVG_EP, phi=aic_lambda_corrected_ricco$phi, theta=aic_lambda_corrected_ricco$theta, d=1, n.ahead = 36,limits = FALSE, plot=TRUE, lastn = TRUE, lambda =c(nonstationary_lambda$model.coef))

forecast_arma_ricco = fore.aruma.wge(df$AVG_EP, phi=overfit_ar_30_i1_ricco$phi,n.ahead = 36,limits = FALSE, plot=TRUE, lastn = TRUE)
## ^^^ YUCK! that looks terrible. let's try a different approach. 

# try finding best long non-stationary estimates Seasonality by rolling window rmse (this has O(n^2) runtime complexity)
best_s_ricco = 0
best_d_ricco = 0
max_s_ricco = 10
max_d_ricco = 2
best_rsme_seasonality_search_and_wandering_search = 10000.0
for (s_try in 0:max_s_ricco) {
  for (d_try in 0:max_d_ricco) {
    rolling.res.long_ricco = roll.win.rmse.wge_ricco(df$AVG_EP, d = d_try, s=s_try, horizon = 36, plot=FALSE)
    if(rolling.res.long_ricco$rwRMSE < best_rsme_seasonality_search_and_wandering_search) {
      best_rsme_seasonality_search_and_wandering_search = rolling.res.long_ricco$rwRMSE
      best_s_ricco = s_try
      best_d_ricco = d_try
    }
  }
}
print(paste("best long rolling window s was:", best_s_ricco))
print(paste("best long rolling window d was:", best_d_ricco))

# best s=0 and d=1 
AVG_E_i1_ricco = artrans.wge(df$AVG_EP, c(1))

# now find best p and q with a rolling window wide grid search
best_p_wide_ricco = 0
best_q_wide_ricco = 0
best_cost_wide_ricco = 10000
best_rsme_s0_d1_p_search_wide = 10000.0
best_last36_ase_wide = 10000.0
q_seq_wide_ricco = seq(1, 11, 5)
p_seq_wide_ricco = seq(0, 30, 10)
for(q_try in q_seq_wide_ricco) {
  for (p_try in p_seq_wide_ricco) {
    was_error = FALSE
    tryCatch(expr = {
      print(paste("trying p: ", p_try, "and q: ", q_try))
      capture.output(est_p_q_search_ricco <- est.arma.wge(AVG_E_i1_ricco, p=p_try, q=q_try), file='NUL')    
      rolling.res.long_ricco = roll.win.rmse.wge_ricco(df$AVG_EP, phi=est_p_q_search_ricco$phi, theta=est_p_q_search_ricco$theta, d=1, s=0,  horizon = 36, plot=FALSE)
      capture.output(f_ricco <- fore.aruma.wge(df$AVG_EP, phi=est_p_q_search_ricco$phi, d=1, s=0, n.ahead=36, lastn=TRUE, plot=FALSE))
      prediction_ase_ricco = mean((df$AVG_EP[(266-35):266]-f$f)^2) 
      # weight last 36 higher because they are the forecasts we should care about most
      cost_ricco = (rolling.res.long_ricco$rwRMSE + prediction_ase_ricco)/2
      if(cost_ricco < best_cost_wide_ricco) {
        best_cost_wide_ricco = cost_ricco
        best_rsme_s0_d1_p_search_wide = rolling.res.long_ricco$rwRMSE
        best_last36_ase_wide = prediction_ase_ricco
        best_p_wide_ricco = p_try
        best_q_wide_ricco = q_try
      }
    },
    error = function(e) {
      print(paste("an error occured for p: ", p_try, "and q: ", q_try))
      was_error = TRUE
    })
    if(was_error)
      next
  }
}
print(paste("best long + immediate rolling window p with wide search was:", best_p_wide_ricco))
print(paste("best long + immediate rolling window q with wide search was:", best_q_wide_ricco))

# now find best p and q with a rolling window narrow grid search
best_p_narrow_ricco = 0
best_q_narrow_ricco = 0
best_cost_narrow_ricco = 10000
best_rsme_s0_d1_p_search_narrow = 10000.0
best_last36_ase_narrow = 10000.0
min_q_narrow_ricco = max(c(1, best_q_wide_ricco-2))
min_p_narrow_ricco = max(c(1, best_p_wide_ricco-4))
q_seq_narrow_ricco = seq(min_q_narrow_ricco, best_q_wide_ricco+1, 1)
p_seq_narrow_ricco = seq(min_p_narrow_ricco, best_p_wide_ricco+2, 1)

best_arma_estimates = NULL
for(q_try in q_seq_narrow_ricco) {
  for (p_try in p_seq_narrow_ricco) {
    was_error = FALSE
    tryCatch(expr = {
      print(paste("trying p: ", p_try, "and q: ", q_try))
      capture.output(est_p_q_search_ricco <- est.arma.wge(AVG_E_i1_ricco, p=p_try, q=q_try), file='NUL')    
      rolling.res.long_ricco = roll.win.rmse.wge_ricco(df$AVG_EP, phi=est_p_q_search_ricco$phi, theta=est_p_q_search_ricco$theta, d=1, s=0,  horizon = 36, plot=FALSE)
      capture.output(f_ricco <- fore.aruma.wge(df$AVG_EP, phi=est_p_q_search_ricco$phi, d=1, s=0, n.ahead=36, lastn=TRUE, plot=FALSE))
      prediction_ase_ricco = mean((df$AVG_EP[(266-35):266]-f$f)^2) 
      # weight last 36 higher because they are the forecasts we should care about most
      cost_ricco = (rolling.res.long_ricco$rwRMSE + prediction_ase_ricco)/2
      if(cost_ricco < best_cost_narrow_ricco) {
        best_cost_narrow_ricco = cost_ricco
        best_rsme_s0_d1_p_search_narrow = rolling.res.long_ricco$rwRMSE
        best_last36_ase_narrow = prediction_ase_ricco
        best_p_narrow_ricco = p_try
        best_q_narrow_ricco = q_try
        best_arma_estimates = est_p_q_search_ricco
      }
    },
    error = function(e) {
      print(paste("an error occured for p: ", p_try, "and q: ", q_try))
      was_error = TRUE
    })
    if(was_error)
      next
  }
}
print(paste("best long + immediate rolling window p with narrow search was:", best_p_narrow_ricco))
print(paste("best long + immediate rolling window q with narrow search was:", best_q_narrow_ricco))

best_rsme_s0_d1_p_search_narrow^2
best_last36_ase_narrow
length(df$AVG_EP)

# best P was p=30 q=11, WOW! A huge and complex model BUT it was rolling window RSME verified!
#  I wonder how the ARIMA(30,1,11) would do on future, unseen data. it’s probably just REALLY good at fitting the signal we have, even if we rolling window verify. true cross-validation would be better, if we had the data.
print(paste("best long rolling (36) ase was:", best_rsme_s0_d1_p_search^2, "for p:", best_p_ricco, "for q:", best_q_ricco, "and d = 1"))

# last 3 ASE
f_ricco_3 = fore.aruma.wge(df$AVG_EP, phi=best_arma_estimates$phi, theta = best_arma_estimates$theta, d=1, s=0, n.ahead=3, lastn=TRUE)
prediction_ase_ricco_3 = mean((df$AVG_EP[(266-3):266]-f_ricco_3$f)^2) 
print(paste("Last 3 ASE was s:", prediction_ase_ricco_3, "for p:", best_p_narrow_ricco, "q:" , best_q_narrow_ricco, "and d = 1"))

# last 36 ASE
f_ricco_36 = fore.aruma.wge(df$AVG_EP, phi=best_arma_estimates$phi, theta = best_arma_estimates$theta, d=1, s=0, n.ahead=36, lastn=TRUE)
prediction_ase_ricco_36 = mean((df$AVG_EP[(266-35):266]-f_ricco_36$f)^2) 
print(paste("Last 36 ASE was s:", prediction_ase_ricco_36, "for p:", best_p_narrow_ricco, "q:" , best_q_narrow_ricco, "and d = 1"))
rolling.res.short_ricco = roll.win.rmse.wge_ricco(df$AVG_EP, phi=best_arma_estimates$phi, theta=best_arma_estimates$theta, d=1, s=0,  horizon = 3, plot=FALSE)

# Rolling 
rolling.res.short_ricco$rwRMSE^2
best_arma_estimates_SSE = sum(best_arma_estimates$res^2)
aic = 266*log(best_arma_estimates_SSE/266) +2*(30+11+1)
aic

# residuals look VERY white, maybe a slight amount of heteroskeascitity and trend at the very end? 
plotts.sample.wge(f_ricco$resid)

# interestingly, ljung box test cannot reject non-stationarity in the residuals! This seems weird. 
ljung.wge(f_ricco$resid)

best_arma_estimates
```


##### A Modified version of current roll.win.rmse.wge in github (uses `fore.aruma.wge` from cran, and doesn't print), to use the latest tswge, replace `fore.aruma.wge` with `fore.arima.wge`)

```{r eval = FALSE, echo = TRUE} 
#Rolling Window RMSE Function
# series is the array of the series
# horizon is how far you want to predict into the future
# d is the order of the differencing: (1-B^)^d
# s is the order of the seasonality: (1-B^s)
# phi = coefficients of the stationary AR term
# theta = coefficients of the invertible MA term

# It simply takes the given horizon and the model in the form of s,d,phis and 
# thetas and figures out how many windows it can create in the data (series) and then calculates the ASE for each window.  
#The output is the average off all the ASEs from each individual window.  

roll.win.rmse.wge_ricco = function(series, horizon = 2, s = 0, d = 0, phi = 0, theta = 0, plot=FALSE)
{

  #DEFINE fore.arma.wge2
  
  fore.arma.wge2=function(x,phi=0,theta=0,n.ahead=5,lastn=FALSE, plot=FALSE,alpha=.05,limits=TRUE, xbar2 = NULL)
  {
    # lastn=TRUE indicates that the last n data values are to be forecast
    # lastn=FALSE (default) indicates we want foreacts for n values beyond the end of the realization
    n=length(x)
    p=length(phi)
    if(sum(phi^2)==0) {p=0}
    q=length(theta)
    if(sum(theta^2)==0) {q=0}
    #resid=rep(0,n)
    npn.ahead=n+n.ahead
    xhat=rep(0,npn.ahead)
    if(is.null(xbar2))
    {
      xbar=mean(x)
    }
    else
    {
      xbar = xbar2
    }
    
    const=1
    if (p > 0) {for(jp in 1:p) {const=const-phi[jp]}}
    #
    #
    # Calculate Box-Jenkins Forecasts
    #
    #
    #Calculating Residuals
    #
    resid=backcast.wge(x,phi,theta,n.back=50)
    #
    #
    #maconst=const*xbar
    #p1=max(p+1,q+1)
    #for (i in p1:n) {resid[i]=x[i]
    #   if ( p > 0) {for (jp in 1:p) {resid[i]=resid[i]-phi[jp]*x[i-jp]}}
    #   if (q > 0) {for (jq in 1:q) {resid[i]=resid[i]+theta[jq]*resid[i-jq]}}
    #                   resid[i]=resid[i]-maconst}
    #
    # Calculating Forecasts
    #
    #
    npn.ahead=n+n.ahead
    xhat=rep(0,npn.ahead)
    mm=n
    #
    #lastn = TRUE
    #
    if(lastn==TRUE) {mm=n-n.ahead}
    #
    #
    for (i in 1:mm) {xhat[i]=x[i]}
    for (h in 1:n.ahead) {
      if (p > 0) {for (jp in 1:p) {xhat[mm+h]=xhat[mm+h]+phi[jp]*xhat[mm+h-jp]}}
      if ((h<=q)&(h>0)) {for(jq in h:q) {xhat[mm+h]=xhat[mm+h]-theta[jq]*resid[mm+h-jq]}}
      xhat[mm+h]=xhat[mm+h]+xbar*const}
    #
    #
    #   Calculate psi weights for forecasts limits
    #
    #
    xi=psi.weights.wge(phi,theta,lag.max=n.ahead)
    #
    #
    #
    #Setting up for plots
    nap1=n.ahead+1
    fplot=rep(0,nap1)
    maxh=mm+n.ahead
    llplot=rep(0,nap1)
    ulplot=rep(0,nap1)
    f=rep(0,nap1)
    ll=rep(0,nap1)
    ul=rep(0,nap1)
    wnv=0
    xisq=rep(0,n.ahead)
    se=rep(0,n.ahead)
    se0=1
    for (i in 1:n) {wnv=wnv+resid[i]**2}
    wnv=wnv/n
    xisq[1]=1
    for (i in 2:n.ahead) {xisq[i]=xisq[i-1]+xi[i-1]^2}
    for (i in 1:n.ahead) {se[i]=sqrt(wnv*xisq[i])}
    fplot[1]=x[mm]
    for (i in 1:n.ahead) {fplot[i+1]=xhat[mm+i]}
    ulplot[1]=x[mm]
    #for (i in 1:n.ahead) { ulplot[i+1]=fplot[i+1]+1.96*se[i]}
    for (i in 1:n.ahead) { ulplot[i+1]=fplot[i+1]-qnorm(alpha/2)*se[i]}
    llplot[1]=x[mm]
    #for (i in 1:n.ahead) { llplot[i+1]=fplot[i+1]-1.96*se[i]}
    for (i in 1:n.ahead) { llplot[i+1]=fplot[i+1]+qnorm(alpha/2)*se[i]}
    #
    if(limits==FALSE) {
      if(lastn==TRUE) {max=max(x,xhat[1:n])
      min=min(x,xhat[1:n])}
      else            {max=max(x,xhat)
      min=min(x,xhat)}}
    if(limits==TRUE) {min=min(x,llplot)
    max=max(x,ulplot)}
    #numrows <- 1
    #numcols <- 1
    timelab <- 'Time'
    valuelab <- ''
    #fig.width <- 5
    #fig.height <- 2.5
    cex.labs <- c(.8,.7,.8)
    #par(mfrow=c(numrows,numcols),mar=c(6,2,3,1))
    t<-1:n;
    np1=n+1
    np.ahead=mm+n.ahead
    tf<-mm:np.ahead
    #if (plot=='TRUE') {
      #fig.width <- 5
      #fig.height <- 2.5
      #cex.labs <- c(1.2,1.2,1.2)
      #par(mfrow=c(numrows,numcols),mar=c(9,4,3,2))
      #plot(t,x,type='o',xaxt='n',yaxt='n',cex=.8,pch=16,cex.lab=1,cex.axis=1,lwd=1,xlab='',ylab='',xlim=c(1,maxh),ylim=c(min,max),col=1)
      #axis(side=1,cex.axis=1.1,mgp=c(3,0.15,0),tcl=-.3);
      #axis(side=2,las=1,cex.axis=1.1,mgp=c(3,.4,0),tcl=-.3)
      #abline=mean(x)
      #mtext(side=c(1,2,1),cex=cex.labs,text=c(timelab,valuelab,""),line=c(1.2,2.1,1.8))
      #points(tf,fplot,type='o',lty=1,cex=.6,lwd=1,pch=1,col=2);
      #if(limits=='TRUE') {points(tf,ulplot,type='l',lty=2,cex=0.6,lwd=.75,pch=1,col=4)
        #points(tf,llplot,type='l',lty=3,cex=0.6,lwd=.75,pch=1,col=4)
     # }
    #}
    np1=n+1
    nap1=n.ahead+1
    f=fplot[2:nap1]
    # Calculate RMSE and MAD
    if(lastn==TRUE){
      t.start=n-n.ahead
      sum.rmse=0
      sum.mad=0
      for(i in 1:n.ahead) {sum.rmse=sum.rmse+(f[i]-x[t.start+i])^2
      sum.mad=sum.mad+abs(f[i]-x[t.start+i])}
      mse=sum.rmse/n.ahead
      rmse=sqrt(mse)
      mad=sum.mad/n.ahead
    }
    ll=llplot[2:nap1]
    ul=ulplot[2:nap1]
    if(lastn==TRUE){out1=list(f=f)}
    if(lastn==FALSE){out1=list(f=f)}
    return(out1)
  }

  
  numwindows = 0
  RMSEHolder = numeric()

  
if(s == 0 & d == 0)
{
  
  trainingSize = max(length(phi),length(theta)) + 1 # The plus 1 is for the backcast residuals which helps with ARMA model with q > 0
  numwindows = length(series)-(trainingSize + horizon) + 1   
  RMSEHolder = numeric(numwindows)

  # print(paste("Please Hold For a Moment, TSWGE is processing the Rolling Window RMSE with", numwindows, "windows."))
  
  for( i in 1:numwindows)
  {
    forecasts <- fore.arma.wge2(series[i:(i+(trainingSize-1))], plot = TRUE, phi = phi, theta = theta,n.ahead = horizon, xbar = mean(series))

    RMSE = sqrt(mean((series[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2))
    
    RMSEHolder[i] = RMSE
  }
}
else
  {
    trainingSize = sum(length(phi),length(theta),s, d) + 1 # sum and plus one is to help backcast.wge, lag.max and ylim plotting issue in fore.arima.wge
    numwindows = length(series)-(trainingSize + horizon) + 1
    RMSEHolder = numeric(numwindows)

    # print(paste("Please Hold For a Moment, TSWGE is processing the Rolling Window RMSE with", numwindows, "windows."))
    
    for( i in 1:numwindows)
    {
      #invisible(capture.output(forecasts <- fore.arima.wge(series[i:(i+(trainingSize-1))],phi = phis, theta = thetas, s = s, d = d,n.ahead = horizon)))
      forecasts <- fore.aruma.wge(series[i:(i+(trainingSize-1))],phi = phi, s = s, d = d, theta = theta,n.ahead = horizon, plot=plot)
      
      RMSE = sqrt(mean((series[(trainingSize+i):(trainingSize+ i + (horizon) - 1)] - forecasts$f)^2))
      
      RMSEHolder[i] = RMSE
      
    }
  }
  
  
  RMSEHolder
  #hist(RMSEHolder, main = "RMSEs for Individual Windows")
  WindowedRMSE = mean(RMSEHolder)
  
  # print("The Summary Statistics for the Rolling Window RMSE Are:")
  # print(summary(RMSEHolder))
  # print(paste("The Rolling Window RMSE is: ",round(WindowedRMSE,3)))

#output
  invisible(list(rwRMSE = WindowedRMSE, trainingSize = trainingSize, numwindows = numwindows, horizon = horizon, s = s, d = d, phi = phi, theta = theta, RMSEs = RMSEHolder))
  
  }
```


